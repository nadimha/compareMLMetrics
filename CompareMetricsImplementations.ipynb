{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285ad0ce-3e5a-4d6c-b5eb-e4445ec75c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install numpy, torchmetrics, skimage, piq, sewar, monai, medpy, tensorflow, torch, cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "beee64a4-15b1-42b3-9eb3-51eb87859513",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image: path_to_image (1).png\n",
      "MONAI: tensor([[0.0788]])\n",
      "torchmetrics: 0.12152284383773804\n",
      "scikit-image: 0.12152182310819626\n",
      "piq: 0.3223619759082794\n",
      "sewar: (0.1593042088876648, 0.20726090685751206)\n",
      "Tensorflow: [0.12152942]\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Image: path_to_image (10).png\n",
      "MONAI: tensor([[0.0569]])\n",
      "torchmetrics: 0.1068655326962471\n",
      "scikit-image: 0.10686403512954712\n",
      "piq: 0.32267075777053833\n",
      "sewar: (0.1462375880774134, 0.18675550519492212)\n",
      "Tensorflow: [0.10686608]\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Image: path_to_image (11).png\n",
      "MONAI: tensor([[0.0307]])\n",
      "torchmetrics: 0.07861389964818954\n",
      "scikit-image: 0.0786123052239418\n",
      "piq: 0.24680687487125397\n",
      "sewar: (0.09691403074957118, 0.13914478270286754)\n",
      "Tensorflow: [0.07861453]\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Image: path_to_image (12).png\n",
      "MONAI: tensor([[0.0830]])\n",
      "torchmetrics: 0.12315180152654648\n",
      "scikit-image: 0.12315205484628677\n",
      "piq: 0.31538277864456177\n",
      "sewar: (0.16749241782848912, 0.2320894537215438)\n",
      "Tensorflow: [0.12315908]\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Image: path_to_image (13).png\n",
      "MONAI: tensor([[0.0829]])\n",
      "torchmetrics: 0.1230958104133606\n",
      "scikit-image: 0.1230960488319397\n",
      "piq: 0.31517288088798523\n",
      "sewar: (0.1674309421086232, 0.2322890911898163)\n",
      "Tensorflow: [0.12310355]\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Image: path_to_image (14).png\n",
      "MONAI: tensor([[0.0338]])\n",
      "torchmetrics: 0.0924917683005333\n",
      "scikit-image: 0.09249456971883774\n",
      "piq: 0.25330814719200134\n",
      "sewar: (0.11267843190737024, 0.17541572490329382)\n",
      "Tensorflow: [0.09249213]\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Image: path_to_image (15).png\n",
      "MONAI: tensor([[0.1013]])\n",
      "torchmetrics: 0.13585996627807617\n",
      "scikit-image: 0.135859414935112\n",
      "piq: 0.32862982153892517\n",
      "sewar: (0.18419043047233571, 0.24857874687816842)\n",
      "Tensorflow: [0.13586141]\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Image: path_to_image (16).png\n",
      "MONAI: tensor([[0.0251]])\n",
      "torchmetrics: 0.0789230689406395\n",
      "scikit-image: 0.07892300933599472\n",
      "piq: 0.22953669726848602\n",
      "sewar: (0.08892737778225114, 0.14605267994851104)\n",
      "Tensorflow: [0.07892651]\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Image: path_to_image (2).png\n",
      "MONAI: tensor([[0.0474]])\n",
      "torchmetrics: 0.09900674223899841\n",
      "scikit-image: 0.09900607913732529\n",
      "piq: 0.2842983305454254\n",
      "sewar: (0.1256979041593726, 0.1683243624340829)\n",
      "Tensorflow: [0.09900876]\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Image: path_to_image (3).png\n",
      "MONAI: tensor([[0.0589]])\n",
      "torchmetrics: 0.1087213084101677\n",
      "scikit-image: 0.1087200865149498\n",
      "piq: 0.3055199086666107\n",
      "sewar: (0.13779201746454486, 0.17849402223882693)\n",
      "Tensorflow: [0.1087229]\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Image: path_to_image (4).png\n",
      "MONAI: tensor([[0.0897]])\n",
      "torchmetrics: 0.13389475643634796\n",
      "scikit-image: 0.13389398157596588\n",
      "piq: 0.3447006046772003\n",
      "sewar: (0.1726386065215971, 0.21718040649412051)\n",
      "Tensorflow: [0.13389565]\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Image: path_to_image (5).png\n",
      "MONAI: tensor([[0.1031]])\n",
      "torchmetrics: 0.1609974503517151\n",
      "scikit-image: 0.16099607944488525\n",
      "piq: 0.43814215064048767\n",
      "sewar: (0.21933454693278462, 0.23903186980788516)\n",
      "Tensorflow: [0.16099155]\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Image: path_to_image (6).png\n",
      "MONAI: tensor([[0.1297]])\n",
      "torchmetrics: 0.17903606593608856\n",
      "scikit-image: 0.17903459072113037\n",
      "piq: 0.467507928609848\n",
      "sewar: (0.25007961504029036, 0.26666288040500935)\n",
      "Tensorflow: [0.17903006]\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Image: path_to_image (7).png\n",
      "MONAI: tensor([[0.0727]])\n",
      "torchmetrics: 0.14900854229927063\n",
      "scikit-image: 0.14901040494441986\n",
      "piq: 0.3958958685398102\n",
      "sewar: (0.1800416128778426, 0.20166028532180214)\n",
      "Tensorflow: [0.14900301]\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Image: path_to_image (8).png\n",
      "MONAI: tensor([[0.0767]])\n",
      "torchmetrics: 0.1271461695432663\n",
      "scikit-image: 0.1271468549966812\n",
      "piq: 0.33671867847442627\n",
      "sewar: (0.16892775042902838, 0.21987247444943817)\n",
      "Tensorflow: [0.12715274]\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Image: path_to_image (9).png\n",
      "MONAI: tensor([[0.1166]])\n",
      "torchmetrics: 0.1554337441921234\n",
      "scikit-image: 0.15543293952941895\n",
      "piq: 0.36168959736824036\n",
      "sewar: (0.20361188327110935, 0.25390960240121535)\n",
      "Tensorflow: [0.15542626]\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Image: path_to_image.png\n",
      "MONAI: tensor([[0.0408]])\n",
      "torchmetrics: 0.08612578362226486\n",
      "scikit-image: 0.08612453192472458\n",
      "piq: 0.2716701924800873\n",
      "sewar: (0.11669826191980981, 0.16333809043077394)\n",
      "Tensorflow: [0.08612826]\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "--- 39.32558512687683 seconds ---\n"
     ]
    }
   ],
   "source": [
    "from abc import ABC\n",
    "import numpy as np\n",
    "from PIL import Image, ImageEnhance, ImageFilter\n",
    "from torchmetrics.image import StructuralSimilarityIndexMeasure as torchMetricsSSIM\n",
    "import skimage.metrics\n",
    "import skimage.util\n",
    "import piq\n",
    "import sewar\n",
    "import monai.metrics.regression\n",
    "from medpy.metric.binary import hd\n",
    "import tensorflow\n",
    "import torch\n",
    "import cv2\n",
    "import io\n",
    "import os\n",
    "import time\n",
    "\n",
    "class ImageProcessor:\n",
    "    \"\"\"\n",
    "    ImageProcessor class for processing images with various transformations.\n",
    "    Attributes:\n",
    "        image (np.ndarray): The image array.\n",
    "    Methods:\n",
    "        __init__(image_path, greyscale=False):\n",
    "            Initializes the ImageProcessor with an image.\n",
    "        unchanged():\n",
    "            Returns the original image.\n",
    "        compressed(format='JPEG', quality=80):\n",
    "            Returns the image compressed to the specified format and quality.\n",
    "        meanshifted(spatial_radius=10, color_radius=10):\n",
    "            Applies mean shift filtering to the image and returns the result.\n",
    "        contrasted(factor=1.0):\n",
    "            Adjusts the contrast of the image by the given factor and returns the result.\n",
    "        gaussian_blurred(radius=2):\n",
    "            Applies Gaussian blur to the image with the specified radius and returns the result.\n",
    "        gaussian_noised(mean=0, std=25):\n",
    "            Adds Gaussian noise to the image with the specified mean and standard deviation and returns the result.\n",
    "    \"\"\"\n",
    "    def __init__(self, image_path, greyscale=False):\n",
    "        if greyscale:\n",
    "            self.image = np.array(Image.open(image_path).convert('L')).clip(0,255).astype(np.uint8)\n",
    "        else:\n",
    "            self.image = np.array(Image.open(image_path).convert('RGB')).clip(0,255).astype(np.uint8)\n",
    "\n",
    "    def unchanged(self):\n",
    "        return self.image\n",
    "\n",
    "    def compressed(self, format='JPEG', quality=80):\n",
    "        img = Image.fromarray(self.image)\n",
    "        img_byte_arr = io.BytesIO()\n",
    "        img.save(img_byte_arr, format=format, quality=quality)\n",
    "        return np.array(Image.open(img_byte_arr)).clip(0,255).astype(np.uint8)\n",
    "\n",
    "    def meanshifted(self, spatial_radius=10, color_radius=10):\n",
    "        return cv2.pyrMeanShiftFiltering(self.image, spatial_radius, color_radius).clip(0,255).astype(np.uint8)\n",
    "\n",
    "    def contrasted(self, factor=1.0):\n",
    "        return np.array(ImageEnhance.Contrast(self.image).enhance(factor)).clip(0,255).astype(np.uint8)\n",
    "\n",
    "    def gaussian_blurred(self, radius=2):\n",
    "        return np.array(Image.fromarray(self.image).filter(ImageFilter.GaussianBlur(radius))).clip(0,255).astype(np.uint8)\n",
    "\n",
    "    def gaussian_noised(self, mean=0, std=25):\n",
    "        gaussian_noise = np.random.normal(mean, std, self.image.shape)\n",
    "        noisy_image = self.image + gaussian_noise\n",
    "        return np.clip(noisy_image, 0, 255).astype(np.uint8)\n",
    "\n",
    "class FullReferenceMetric(ABC):\n",
    "    \"\"\"\n",
    "    FullReferenceMetric is an abstract base class for full-reference image quality metrics.\n",
    "\n",
    "    Methods:\n",
    "        compute(image1, image2):\n",
    "            Computes the metric values for the given pair of images.\n",
    "            \n",
    "            Parameters:\n",
    "                image1 (ndarray): The first image to compare.\n",
    "                image2 (ndarray): The second image to compare.\n",
    "            \n",
    "            Returns:\n",
    "                dict: A dictionary where keys are metric names and values are the computed metric results.\n",
    "    \"\"\"\n",
    "    def compute(self, image1, image2):\n",
    "        results = {}\n",
    "        for key, value in self.__class__.implementations.items():\n",
    "            image1_transformed = None\n",
    "            image2_transformed = None\n",
    "            for transform in value[2]:\n",
    "                image1_transformed = transform(image1)\n",
    "                image2_transformed = transform(image2)\n",
    "            results[key] = value[0](image1_transformed, image2_transformed, **value[1])\n",
    "        return results\n",
    "\n",
    "\n",
    "class SSIM(FullReferenceMetric):\n",
    "    \"\"\"\n",
    "    SSIM (Structural Similarity Index Metric) class for computing the SSIM metric using various implementations.\n",
    "\n",
    "    Attributes:\n",
    "        implementations (dict): A dictionary where keys are the names of different SSIM implementations and values are tuples containing:\n",
    "            - The SSIM computation function from the respective library.\n",
    "            - A dictionary of keyword arguments to be passed to the SSIM computation function.\n",
    "            - A list of preprocessing functions to be applied to the input image before computing SSIM.\n",
    "\n",
    "    Supported Implementations:\n",
    "        - \"MONAI\": Uses `monai.metrics.regression.SSIMMetric`.\n",
    "        - \"torchmetrics\": Uses `torchmetrics.functional.ssim`.\n",
    "        - \"scikit-image\": Uses `skimage.metrics.structural_similarity`.\n",
    "        - \"piq\": Uses `piq.ssim`.\n",
    "        - \"sewar\": Uses `sewar.full_ref.ssim`.\n",
    "        - \"Tensorflow\": Uses `tensorflow.image.ssim`.\n",
    "    \"\"\"\n",
    "    implementations = {\"MONAI\": (monai.metrics.regression.SSIMMetric(spatial_dims=2)._compute_metric, {}, [lambda image : torch.tensor(image).unsqueeze(0).permute(0, 3, 1, 2).float()]),\n",
    "                       \"torchmetrics\": (torchMetricsSSIM(data_range = 255.0),{}, [lambda image : torch.tensor(image).unsqueeze(0).permute(0, 3, 1, 2).float()]),\n",
    "                       \"scikit-image\": (skimage.metrics.structural_similarity,{\"gaussian_weights\" : True, \"sigma\" : 1.5, \"use_sample_covariance\" : False, \"data_range\" : 255, \"channel_axis\" : -1}, [lambda image : torch.tensor(image).float().numpy()]),\n",
    "                       \"piq\": (piq.ssim, {\"data_range\": 255}, [lambda image : torch.tensor(image).unsqueeze(0).permute(0, 3, 1, 2).float()]),\n",
    "                       \"sewar\" : (sewar.full_ref.ssim,{\"MAX\" : 255}, [lambda image : torch.tensor(image).squeeze().float().numpy()]),\n",
    "                       \"Tensorflow\": (tensorflow.image.ssim,{\"max_val\" : 255}, [lambda image : torch.tensor(image).unsqueeze(0).float()])}\n",
    "\n",
    "def test_metrics_on_images(image1, image2, metric):\n",
    "    for implementation, result in metric.compute(image1, image2).items():\n",
    "        print(f\"{implementation}: {result}\")\n",
    "\n",
    "def get_image_files_in_directory(directory_path):\n",
    "    return [os.path.join(directory_path, file) for file in os.listdir(directory_path) if file.endswith(('png', 'jpg', 'jpeg'))]\n",
    "\n",
    "# Apply on a directory\n",
    "directory_path = \"path_to_directory\"\n",
    "\n",
    "def run_on_directory():\n",
    "    images = get_image_files_in_directory(directory_path)\n",
    "    for image_path in images:\n",
    "            print(f\"Image: {image_path}\")\n",
    "            imageProcessor = ImageProcessor(image_path)\n",
    "            test_metrics_on_images(imageProcessor.unchanged(), imageProcessor.gaussian_noised(mean = 3, std = 30), SSIM())\n",
    "            print(\"\\n\" + \"-\"*50 + \"\\n\")\n",
    "\n",
    "# Apply on a single image\n",
    "def run_on_single_image():\n",
    "    image_path = \"path_to_image\"\n",
    "    imageProcessor = ImageProcessor(image_path, greyscale=True)\n",
    "    test_metrics_on_images(imageProcessor.unchanged(), imageProcessor.gaussian_blurred(radius=10), SSIM())\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "run_on_directory()\n",
    "\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
